Skip to main content
Google Classroom
Classroom
DevOps with AWS @ 4:00 PM | Mr.Raham [28th Aug]
Mr.Raham
Home
Calendar
Enrolled
To do
D
DevOps with AWS @ 4:00 PM | Mr.Raham [28th Aug]
Mr.Raham
Q
Quantitative Aptitude - II
C
Cloud Scripting using PAAS
BCA-VI
B
BCA_Cloud_Web_Services
BCA_CC
P
Programming in C
BCA
C
COMPUTER APPLICATION
BCA
Archived classes
Settings
Stream
Classwork
People
DevOps with AWS @ 4:00 PM | Mr.Raham [28th Aug]
Mr.Raham
Upcoming
Woohoo, no work due in soon!
Material
Raham posted a new material: MONITORING CLASS
Posted 5 Oct

p & g.txt
Text

Announcement: 'ASSIGNMENT-4: CREATE ALL THE RESOURCES…'
Raham
Created 4 Oct4 Oct
ASSIGNMENT-4:
CREATE ALL THE RESOURCES FROM ASSIGMANET NUMBER-1 BUT ON TERRAFORM CLOUD.
PUT THE ASSIGMNET-1 CODE IN GITHUB
ENABLE : COST ESTIMIZATION
DESTROY ALL THE RESOURCES.

CREATE 10 SERVERS MANUALLY & IMPORT THEM USING IMPORT COMMAND.
Material
Raham posted a new material: HCP & LAST CLASS
Posted 3 Oct (Edited 4 Oct)

HCP.txt
Text
Assignment
Raham posted a new assignment: ASSIGNMENTS:
Posted 1 Oct
Assigned
ASSIGNMENT-1:

1. CREATE A VPC, SUBNET, IGW, ROUTE-TABLE AND ATTACH TO SERVER.
2. SERVER NEED TO CREATE ON US-EAST-1B AZ.
3. SERVER NEED TO HAVE KEY-PAIR WHICH GENERTED BY TLS PROVIDER.
4. PROVIDER VERSIONS (AWS=5.68.0, TLS=4.0.5, LOCAL=2.5.0)
5. STATEFILE MUST BE ON S3 BUCKET.
6. AFTER CREATING RESOURCE SET BACKEND STATE FILE FROM S3 TO LOCAL.

NOTE: ONCE VPC CREATED THEN ONLY SUBNET NEED TO CREATE.

ASSIGNMENT-2:
DEPLOY THE AMAZON APP THROUGH TERRAFORM
ATTACH A LOADBALANCER TO THER SERVERS
OUTPUT OF LOADBALANCER DNS NEED TO PRINT OF SCREEN.

PROMPT: GENERATE A TERRAFORM CODE TO ATTACH 2 SERVERS TO A LOADBALANCER
CODE: AMAZON: https://github.com/Ironhack-Archive/online-clone-amazon.git

Announcement: 'ASSIGNMENT-1: 1. CREATE A VPC, SUBNET,…'
Raham
Created 30 Sept30 Sept
ASSIGNMENT-1:

1. CREATE A VPC, SUBNET, IGW, ROUTE-TABLE AND ATTACH TO SERVER.
2. SERVER NEED TO CREATE ON US-EAST-1B AZ.
3. SERVER NEED TO HAVE KEY-PAIR WHICH GENERTED BY TLS PROVIDER.
4. PROVIDER VERSIONS (AWS=5.68.0, TLS=4.0.5, LOCAL=2.5.0)
5. STATEFILE MUST BE ON S3 BUCKET.
6. AFTER CREATING RESOURCE SET BACKEND STATE FILE FROM S3 TO LOCAL.

Announcement: 'Dear students, Please clear the due…'
Naresh IT
Created 30 Sept30 Sept (Edited 30 Sept)
Dear students,

Please clear the due amounts as soon as possible [by 1st week of Oct] if not the access will be removed.
Material
Raham posted a new material: TERRAFORM PDFS
Posted 26 Sept (Edited 2 Oct)
FOR IMPORT:

vim main.tf

import {
to = aws_instance.one
id = "instance-id"
}

terraform plan -generate-config-out=ec2.tf
terraform apply

CODE:

provider "aws" {
region = "us-east-1"
}

resource "aws_instance" "one" {
count = 2
ami = "ami-0ebfd941bbafe70c6"
instance_type = "t2.micro"
tags = {
Name = "${terraform.workspace}-server"
}
}

======================================
DATA BLOCK CODE:

data "aws_ami" "example" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}

resource "aws_instance" "example_instance" {
  ami           = data.aws_ami.example.id
  instance_type = "t2.micro"
}

cat main.tf
provider "aws" {
}

module "my_instance" {
source = "./modules/instances"
}

module "s3_module" {
source = "./modules/buckets"
}

mkdir -p modules/instances
mkdir -p modules/buckets

cat modules/buckets/main.tf
resource "aws_s3_bucket" "abcd" {
bucket = "devopsherahamshaik0099889977"
}


cat modules/instance/main.tf
resource "aws_instance" "three" {
  count         = 2
  ami           = "ami-00b8917ae86a424c9"
  instance_type = "t2.medium"
  key_name      = "yterraform"
  tags = {
    Name = "n.virginia-server"
  }
}


PROVISIONERS: used to execute commamds or scripts in terraform managed resources on both local and remote.

LOCAL-EXEC: used to execute a command or script on local machine (where terraform is installed)
it will execute the command when resource is created


provider "aws" {
}

resource "aws_instance" "one" {
  ami           = "ami-04823729c75214919"
  instance_type = "t2.micro"
  tags = {
    instance_name = "rahaminstance"
  }
  provisioner "local-exec" {
    command = "echo my name is raham"
  }
}


remote exec: is used to run the commands on remote servers.
once the server got created it will execute the commands and scripts for installing the softwares and configuring them and even for deployment also.


provider "aws" {
}

resource "aws_instance" "one" {
  ami           = "ami-04823729c75214919"
  instance_type = "t2.micro"
  key_name      = "yterraform"
  tags = {
    Name = " rahaminstance"
  }

  provisioner "remote-exec" {
    inline = [
      "sudo yum update -y",
      "sudo yum install git maven tree httpd -y",
      "touch file1"
    ]

    connection {
      type        = "ssh"
      user        = "ec2-user"
      private_key = file("~/.ssh/id_rsa")
      host        = self.public_ip
    }
  }
}

TERRAFORM-003 (4).pdf
PDF

Announcement: 'Hi, Please join the online class with…'
Naresh IT
Created 26 Sept26 Sept
Hi,

Please join the online class with the link below:

DevOps @ 4:00 PM (IST) by Mr.Raham_New_Link [28-09-2024]
Meeting Link: https://nareshitechnologies.webex.com/nareshitechnologies/j.php?MTID=m3c5f596cb9a71713af7a3fc940f14455
Joining URL: https://web.webex.com/join-meeting
Meeting Id: 2519 237 2230
Password: 574803
Material
Raham posted a new material: DAILY NOTES
Posted 23 Sept (Edited 9 Oct)

28-08-2024.txt
Text

Announcement: 'Dear offline Students, Reminder about…'
Ajay Naresh IT
Created 23 Sept23 Sept
Dear offline Students,
Reminder about your ID cards.
Those who are attending the regular classes and Lab should have compalsary ID card. If any one don't have Please come Tomorrow with your Original payment receipts and also with one passport size photo to the campus only so that will provide you the ID Card within 5 Min.

*NOTE
FROM WEDNESDAY THOSE WHO ARE NOT HAVING ID CARDS WILL NOT ALLOWED TO CLASSES AND ALSO LAB*
DevOps with AWS @ 4:00 PM | Mr.Raham [28th Aug] Mr.Raham
PROMETHEUS:

Prometheus is an open-source monitoring system that is especially well-suited for cloud-native environments, like Kubernetes. 
It can monitor the performance of your applications and services.
it will sends an alert you if there are any issues. 
It has a powerful query language that allows you to analyze the data.
It pulls the real-time metrics, compresses and stores  in a time-series database.
Prometheus is a standalone system, but it can also be used in conjunction with other tools like Alertmanager to send alerts based on the data it collects.
it can be integration with tools like PagerDuty, Teams, Slack, Emails to send alerts to the appropriate on-call personnel.
it collects, and it also has a rich set of integrations with other tools and systems.
For example, you can use Prometheus to monitor the health of your Kubernetes cluster, and use its integration with Grafana to visualize the data it collects.

COMPONENTS OF PROMETHEUS:
Prometheus is a monitoring system that consists of the following components:

A main server that scrapes and stores time series data
A query language called PromQL is used to retrieve and analyze the data
A set of exporters that are used to collect metrics from various systems and applications
A set of alerting rules that can trigger notifications based on the data
An alert manager that handles the routing and suppression of alerts

GRAFANA:
Grafana is an open-source data visualization and monitoring platform that allows you to create dashboards to visualize your data and metrics. 
It is a popular choice for visualizing time series data, and it integrates with a wide range of data sources, including Prometheus, Elasticsearch, and InfluxDB.
A user-friendly interface that allows you to create and customize dashboards with panels that display your data in a variety of formats, including graphs, gauges, and tables. You can also use Grafana to set up alerts that trigger notifications when certain conditions are met.
Grafana has a rich ecosystem of plugins and integrations that extend its functionality. For example, you can use Grafana to integrate with other tools and services, such as Slack or PagerDuty, to receive alerts and notifications.
Grafana is a powerful tool for visualizing and monitoring your data and metrics, and it is widely used in a variety of industries and contexts.

CONNECTION:
SETUP BOTH PROMETHEUS & GRAFAN FROM BELOW LINK
https://github.com/RAHAMSHAIK007/all-setups.git

pROMETHERUS: 9090
NODE EXPORTER: 9100
GRAFANA: 3000


SYNOPSIS:

NODE EXPORTER:
collects metrics of worker nodes
in each worker node we need to install node exporter
Port: 9100

PROMETEUS:
its a free & opensource monitoring tool
it collects metrics of servers
it store metrics on time series database
we use PromQL language 
we can integrate promethus with tools like
pagerduty, slack and email to send notifications
PORT: 9090

GRAFANA:
its a visualization tool used to create dashboard.
Data source is main component (from where you are getting data)
Prometheus will show data but cant create dashboards
Dashboards: create, Import  
we can integrate Grafana with tools like
pagerduty, slack and email to send notifications
PORT: 3000

username & passowrd: admin & admin

CONNECTING PROMETHEUS TO GARAFANA:
connect to grafana dashboard -- > Data source -- > add -- > promethus -- > url of prometheus -- > save & test -- > top of page -- >click on + symbol -- >  import dashboard -- > 1860 -- > laod --- > prometheus -- > import 

amazon-linux-extras install epel -y
yum install stress -y

STILL IM CONNECTING TO MONITORING SERVER.


CONNECTING TO WORKER NODES:

Craete 2 servers and install node exporter
go to main server and 

vim /etc/hosts
public-ip node1  worker-1
public-ip node2  worker-2


NOTE: TO CREATE DASHBOARDS IN GRAFANA WE NEED 
1. ID
2. DATA SOURCE
3. DEPENDENCY

10180
14731

--- > below one is not the class topic
INFLUX DB INSTALLATION:

curl -LO https://download.influxdata.com/influxdb/releases/influxdb2-2.7.8-1.x86_64.rpm
sudo yum localinstall influxdb2-2.7.8-1.x86_64.rpm
sudo service influxdb start
sudo service influxdb status
p & g.txt
Displaying p & g.txt.



Working:------------------------------------------------------
1.launch an AMI-2 and connect it.
2.vim pigeon.sh: -


#prometheus
wget https://github.com/prometheus/prometheus/releases/download/v2.43.0/prometheus-2.43.0.linux-amd64.tar.gz
tar -xf prometheus-2.43.0.linux-amd64.tar.gz
sudo mv prometheus-2.43.0.linux-amd64/prometheus prometheus-2.43.0.linux-amd64/promtool /usr/local/bin

Now, We need to Create directories for configuration files and other prometheus data.
sudo mkdir /etc/prometheus /var/lib/prometheus
sudo mv prometheus-2.43.0.linux-amd64/console_libraries /etc/prometheus
ls /etc/prometheus
sudo rm -rvf prometheus-2.43.0.linux-amd64*

#sudo vim /etc/hosts
#3.101.56.72  worker-1
#54.193.223.22 worker-2

sudo cat <<EOF | sudo tee /etc/prometheus/prometheus.yml
global:
  scrape_interval: 10s

scrape_configs:
  - job_name: 'prometheus_metrics'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:9090']
  - job_name: 'node_exporter_metrics'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:9100','worker-1:9100','worker-2:9100']
EOF


sudo useradd -rs /bin/false prometheus
sudo chown -R prometheus: /etc/prometheus /var/lib/prometheus

 sudo ls -l /etc/prometheus/
sudo cat <<EOF | tee /etc/systemd/system/prometheus.service
[Unit]
Description=Prometheus
After=network.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/usr/local/bin/prometheus \
    --config.file /etc/prometheus/prometheus.yml \
    --storage.tsdb.path /var/lib/prometheus/ \
    --web.console.templates=/etc/prometheus/consoles \
    --web.console.libraries=/etc/prometheus/console_libraries

[Install]
WantedBy=multi-user.target
EOF

sudo ls -l /etc/systemd/system/prometheus.service
sudo systemctl daemon-reload && sudo systemctl enable prometheus
sudo systemctl start prometheus && sudo systemctl status prometheus --no-pager

#GRAFANA
wget -q -O gpg.key https://rpm.grafana.com/gpg.key
sudo rpm --import gpg.key
sudo cat <<EOF | tee /etc/yum.repos.d/grafana.repo
[grafana]
name=grafana
baseurl=https://rpm.grafana.com
repo_gpgcheck=1
enabled=1
gpgcheck=1
gpgkey=https://rpm.grafana.com/gpg.key
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
EOF

exclude=*beta*
yum install grafana -y
systemctl start grafana-server.service
systemctl status grafana-server.service

#NODEEXPORTER
wget https://github.com/prometheus/node_exporter/releases/download/v1.5.0/node_exporter-1.5.0.linux-amd64.tar.gz
tar -xf node_exporter-1.5.0.linux-amd64.tar.gz
sudo mv node_exporter-1.5.0.linux-amd64/node_exporter  /usr/local/bin
rm -rv node_exporter-1.5.0.linux-amd64*
sudo useradd -rs /bin/false node_exporter

sudo cat <<EOF | sudo tee /etc/systemd/system/node_exporter.service
[Unit]
Description=Node Exporter
After=network.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter

[Install]
WantedBy=multi-user.target
EOF

sudo cat /etc/systemd/system/node_exporter.service
sudo systemctl daemon-reload  && sudo systemctl enable node_exporter
sudo systemctl start node_exporter.service && sudo systemctl status node_exporter.service --no-pager




3. sh pigeon.sh
4. open the public ip :
   prometheus: 9090
   grafana: 3000
   node_exporter: 9100